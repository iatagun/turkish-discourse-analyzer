"""
Stanza'nÄ±n gerÃ§ek POS tagging hatalarÄ±nÄ± merkezleme kuramÄ± ile dÃ¼zeltme demosu
"""
from dataclasses import dataclass
from enum import Enum
from typing import List, Optional, Tuple
import torch

# PyTorch weights_only workaround
_orig_load = torch.load
def _load(*args, **kwargs):
    kwargs.setdefault("weights_only", False)
    return _orig_load(*args, **kwargs)
torch.load = _load

import stanza


@dataclass
class Token:
    form: str
    upos: str
    head: int
    deprel: str


@dataclass
class CenteringState:
    forward_centers: List[str]
    backward_center: Optional[str]
    preferred_center: Optional[str]
    pronoun_resolutions: Optional[dict] = None

    def __post_init__(self):
        if self.pronoun_resolutions is None:
            self.pronoun_resolutions = {}


class TransitionType(Enum):
    CONTINUE = "Continue"
    RETAIN = "Retain"
    SMOOTH_SHIFT = "Smooth-Shift"
    ROUGH_SHIFT = "Rough-Shift"


def resolve_pronouns(tokens: List[Token], prev_state: Optional[CenteringState]) -> dict:
    """GELÄ°ÅTÄ°RÄ°LMÄ°Å Zamir Ã§Ã¶zÃ¼mlemesi - SayÄ± uyumu ve animacy kontrolÃ¼ ile"""
    turkish_pronouns = {
        'o': {'type': 'personal', 'number': 'singular'},
        'onlar': {'type': 'personal', 'number': 'plural'},
        'bu': {'type': 'demonstrative', 'number': 'singular'},
        'bunlar': {'type': 'demonstrative', 'number': 'plural'},
    }
    
    # Animacy (canlÄ±lÄ±k) sÃ¶zlÃ¼ÄŸÃ¼ - TÃ¼rkÃ§e iÃ§in geniÅŸletilebilir
    animate_entities = {
        'ahmet', 'ali', 'ayÅŸe', 'mehmet', 'fatma', 'Ã§ocuk', 'Ã¶ÄŸretmen', 
        'Ã¶ÄŸrenci', 'Ã¶ÄŸrenciler', 'kedi', 'kÃ¶pek', 'kuÅŸ', 'insan', 'insanlar',
        'mÃ¼hendisi', 'doktor', 'hemÅŸire', 'adam', 'kadÄ±n', 'erkek', 'kÄ±z', 'oÄŸlan'
    }
    
    def is_plural(word: str) -> bool:
        # BileÅŸik isimler iÃ§in '_' ile ayÄ±r ve ilk kelimeyi kontrol et
        if '_' in word:
            first_word = word.split('_')[0]
            return first_word.endswith(('ler', 'lar'))
        return word.endswith(('ler', 'lar', 'lere', 'lara', 'lerde', 'larda'))
    
    def is_animate(word: str) -> bool:
        """VarlÄ±ÄŸÄ±n canlÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol et"""
        word_lower = word.lower()
        # DoÄŸrudan eÅŸleÅŸme
        if word_lower in animate_entities:
            return True
        # Ä°sim Ã¶beÄŸi kontrolÃ¼ (Ã¶rn: "yazÄ±lÄ±m mÃ¼hendisi")
        for entity in animate_entities:
            if entity in word_lower or word_lower in entity:
                return True
        return False
    
    resolutions = {}
    
    if prev_state is None or not prev_state.forward_centers:
        return resolutions
    
    for tok in tokens:
        # âš ï¸ KRITIK: Sadece PRON etiketli tokenlarÄ± iÅŸle
        if tok.upos != "PRON":
            continue
        
        tok_lower = tok.form.lower()
        if tok_lower in turkish_pronouns:
            pron_info = turkish_pronouns[tok_lower]
            best_match = None
            best_score = -1
            
            for idx, prev_center in enumerate(prev_state.forward_centers):
                score = 0.0
                
                # 1. SAYICI UYUMU (GELÄ°ÅTÄ°RÄ°LMÄ°Å) - Uyumsuzluk varsa aÄŸÄ±r ceza
                center_is_plural = is_plural(prev_center)
                pronoun_is_plural = (pron_info['number'] == 'plural')
                
                if pronoun_is_plural == center_is_plural:
                    score += 15.0  # Tam uyum - yÃ¼ksek bonus
                else:
                    score -= 25.0  # Uyumsuzluk - aÄŸÄ±r ceza!
                
                # 2. ANIMACY BONUS - ÅahÄ±s zamirleri iÃ§in canlÄ± varlÄ±klar tercih edilir
                if pron_info['type'] == 'personal' and is_animate(prev_center):
                    score += 15.0  # CanlÄ± varlÄ±k - gÃ¼Ã§lÃ¼ bonus
                elif pron_info['type'] == 'personal' and not is_animate(prev_center):
                    score -= 20.0  # CansÄ±z varlÄ±ÄŸa ÅŸahÄ±s zamiri - aÄŸÄ±r ceza
                
                # 3. Pozisyon skoru
                position_score = (len(prev_state.forward_centers) - idx) / len(prev_state.forward_centers)
                score += position_score * 3.0
                
                # 4. Base skor
                score += 2.0
                
                if score > best_score:
                    best_score = score
                    best_match = prev_center
            
            # Sadece yÃ¼ksek skorlu eÅŸleÅŸmeleri kabul et (threshold: 5)
            if best_match and best_score > 5:
                resolutions[tok_lower] = best_match
    
    return resolutions


def detect_noun_phrases(tokens: List[Token]) -> dict:
    """GELÄ°ÅTÄ°RME: Ä°sim Ã¶beklerini (noun phrases) tespit et"""
    noun_phrases = {}
    
    # Basit heuristik: Art arda gelen NOUN/ADJ + NOUN birleÅŸimleri
    i = 0
    while i < len(tokens):
        if i < len(tokens) - 1:
            curr_tok = tokens[i]
            next_tok = tokens[i + 1]
            
            # SÄ±fat + Ä°sim veya Ä°sim + Ä°sim (bileÅŸik isim)
            if ((curr_tok.upos in {"ADJ", "NOUN"} and next_tok.upos == "NOUN") or
                (curr_tok.upos == "NOUN" and next_tok.upos == "NOUN" and 
                 next_tok.deprel in {"nmod", "compound"})):
                # BileÅŸik isim bulundu
                phrase = f"{curr_tok.form.lower()}_{next_tok.form.lower()}"
                noun_phrases[next_tok.form.lower()] = phrase
                noun_phrases[curr_tok.form.lower()] = phrase
                i += 2
                continue
        i += 1
    
    return noun_phrases


def compute_forward_centers(tokens: List[Token], pronoun_resolutions: Optional[dict] = None) -> List[str]:
    """GELÄ°ÅTÄ°RÄ°LMÄ°Å Forward centers - Noun phrase chunking ile"""
    if pronoun_resolutions is None:
        pronoun_resolutions = {}
    
    # Ä°sim Ã¶beklerini tespit et
    noun_phrases = detect_noun_phrases(tokens)
    
    salience_weights = {
        "nsubj": 4,
        "obj": 3,
        "obl": 2,
        "nmod": 1,
    }
    pos_weights = {
        "PRON": 3,
        "PROPN": 2,
        "NOUN": 1,
    }

    centers = []
    processed_indices = set()
    
    for i, tok in enumerate(tokens):
        if i in processed_indices:
            continue
            
        tok_lower = tok.form.lower()
        
        # Zamir Ã§Ã¶zÃ¼mlemesi varsa
        if tok_lower in pronoun_resolutions:
            referent = pronoun_resolutions[tok_lower]
            salience = 0.0
            if tok.deprel in salience_weights:
                salience += salience_weights[tok.deprel]
            salience += pos_weights.get("PRON", 3)
            position_weight = 1.0 - (i / max(1, len(tokens)))
            salience += position_weight
            centers.append((referent, salience, i))
            continue
        
        if tok.upos not in {"NOUN", "PROPN", "PRON"}:
            continue
        
        # Ä°sim Ã¶beÄŸi kontrolÃ¼
        entity = noun_phrases.get(tok_lower, tok_lower)
        
        salience = 0.0
        if tok.deprel in salience_weights:
            salience += salience_weights[tok.deprel]
        if tok.upos in pos_weights:
            salience += pos_weights[tok.upos]
        
        # Ä°sim Ã¶beÄŸi ise bonus
        if '_' in entity:
            salience += 2.0  # BileÅŸik isim bonusu
        
        position_weight = 1.0 - (i / max(1, len(tokens)))
        salience += position_weight
        centers.append((entity, salience, i))

    centers.sort(key=lambda x: (-x[1], x[2]))
    seen = set()
    ordered = []
    for center, _, _ in centers:
        if center not in seen:
            seen.add(center)
            ordered.append(center)
    return ordered[:5]


def compute_transition(prev_state: Optional[CenteringState], current_cf: List[str], 
                       pronoun_resolutions: Optional[dict] = None) -> Tuple[Optional[TransitionType], CenteringState]:
    if pronoun_resolutions is None:
        pronoun_resolutions = {}
    
    cp = current_cf[0] if current_cf else None

    if prev_state is None:
        state = CenteringState(
            forward_centers=current_cf, 
            backward_center=None, 
            preferred_center=cp, 
            pronoun_resolutions=pronoun_resolutions
        )
        return None, state

    prev_cb = prev_state.backward_center
    cb = None
    for prev_center in prev_state.forward_centers:
        if prev_center in current_cf:
            cb = prev_center
            break

    if cb is None:
        transition = TransitionType.ROUGH_SHIFT
    else:
        if prev_cb == cb and cb == cp:
            transition = TransitionType.CONTINUE
        elif prev_cb == cb and cb != cp:
            transition = TransitionType.RETAIN
        elif prev_cb != cb and cb == cp:
            transition = TransitionType.SMOOTH_SHIFT
        else:
            transition = TransitionType.ROUGH_SHIFT

    state = CenteringState(
        forward_centers=current_cf, 
        backward_center=cb, 
        preferred_center=cp, 
        pronoun_resolutions=pronoun_resolutions
    )
    return transition, state


def transition_score(transition: Optional[TransitionType]) -> int:
    if transition is None:
        return 1
    weights = {
        TransitionType.CONTINUE: 3,
        TransitionType.RETAIN: 2,
        TransitionType.SMOOTH_SHIFT: 2,
        TransitionType.ROUGH_SHIFT: 1,
    }
    return weights.get(transition, 0)


def score_parse(tokens: List[Token], prev_state: Optional[CenteringState]) -> Tuple[int, CenteringState]:
    pronoun_resolutions = resolve_pronouns(tokens, prev_state)
    cf = compute_forward_centers(tokens, pronoun_resolutions)
    transition, state = compute_transition(prev_state, cf, pronoun_resolutions)
    return transition_score(transition), state


def parse_with_stanza(nlp, text: str) -> List[Token]:
    """Stanza ile cÃ¼mleyi parse et"""
    doc = nlp(text)
    if not doc.sentences:
        return []
    
    sent = doc.sentences[0]
    tokens = []
    for word in sent.words:
        tokens.append(Token(
            form=word.text,
            upos=word.upos,
            deprel=word.deprel,
            head=word.head
        ))
    return tokens


def test_sentence_pair(nlp, sent1: str, sent2: str):
    """Ä°ki cÃ¼mleyi test et ve merkezleme kuramÄ± analizini gÃ¶ster"""
    print("\n" + "="*80)
    print(f"ğŸ“ CÃ¼mle 1: {sent1}")
    print(f"ğŸ“ CÃ¼mle 2: {sent2}")
    print("="*80)
    
    # CÃ¼mle 1
    tokens1 = parse_with_stanza(nlp, sent1)
    print(f"\nğŸ” CÃ¼mle 1 - Stanza POS Tagging:")
    for tok in tokens1:
        print(f"  {tok.form:15} â†’ {tok.upos:8} ({tok.deprel})")
    
    score1, state1 = score_parse(tokens1, None)
    print(f"\n  Cf: {state1.forward_centers[:3]}")
    print(f"  Cb: {state1.backward_center or 'YOK'}")
    print(f"  Skor: {score1}")
    
    # CÃ¼mle 2
    tokens2 = parse_with_stanza(nlp, sent2)
    print(f"\nğŸ” CÃ¼mle 2 - Stanza POS Tagging:")
    for tok in tokens2:
        marker = "âš ï¸" if tok.form.lower() in ['o', 'bu', 'onlar', 'bunlar'] and tok.upos != "PRON" else "âœ…"
        print(f"  {marker} {tok.form:15} â†’ {tok.upos:8} ({tok.deprel})")
    
    # Zamir Ã§Ã¶zÃ¼mlemesi
    pronoun_resolutions = resolve_pronouns(tokens2, state1)
    if pronoun_resolutions:
        print(f"\n  ğŸ”— Zamir Ã‡Ã¶zÃ¼mlemesi:")
        for pron, ref in pronoun_resolutions.items():
            print(f"    '{pron}' â†’ '{ref}'")
    else:
        print(f"\n  âš ï¸  Zamir Ã§Ã¶zÃ¼mlemesi yapÄ±lamadÄ±!")
        print(f"      (Muhtemelen 'o', 'bu' gibi kelimeler PRON olarak etiketlenmedi)")
    
    score2, state2 = score_parse(tokens2, state1)
    cf2 = compute_forward_centers(tokens2, pronoun_resolutions)
    transition2, _ = compute_transition(state1, cf2, pronoun_resolutions)
    
    print(f"\n  Cf: {state2.forward_centers[:3]}")
    print(f"  Cb: {state2.backward_center or 'YOK'}")
    print(f"  GeÃ§iÅŸ: {transition2.value if transition2 else 'Ä°LK CÃœMLE'}")
    print(f"  Skor: {score2}")
    
    # Analiz
    print("\n" + "â”€"*80)
    if pronoun_resolutions:
        print("âœ… BAÅARILI: Zamir Ã§Ã¶zÃ¼mlemesi Ã§alÄ±ÅŸtÄ±")
        print("   â†’ Merkezleme kuramÄ± Stanza'nÄ±n doÄŸru etiketlemesini destekliyor")
    else:
        print("âŒ SORUN: Zamir Ã§Ã¶zÃ¼mlemesi baÅŸarÄ±sÄ±z")
        print("   â†’ Stanza muhtemelen zamiri yanlÄ±ÅŸ etiketledi (NOUN olarak)")
        print("   â†’ Merkezleme kuramÄ± bu hatayÄ± dÃ¼ÅŸÃ¼k skor ile tespit edebilir")


def analyze_error_type(nlp, error_type: str, description: str, correct_pair: tuple, wrong_pair: tuple):
    """Belirli bir hata tÃ¼rÃ¼nÃ¼ analiz et ve karÅŸÄ±laÅŸtÄ±r - GELÄ°ÅTÄ°RÄ°LMÄ°Å"""
    print("\n" + "="*80)
    print(f"ğŸ” HATA TÃœRÃœ: {error_type}")
    print(f"ğŸ“‹ {description}")
    print("="*80)
    
    # DoÄŸru versiyonu test et
    print(f"\nâœ… DOÄRU VERSÄ°YON:")
    print(f"   CÃ¼mle 1: {correct_pair[0]}")
    print(f"   CÃ¼mle 2: {correct_pair[1]}")
    
    tokens1_correct = parse_with_stanza(nlp, correct_pair[0])
    tokens2_correct = parse_with_stanza(nlp, correct_pair[1])
    
    score1_c, state1_c = score_parse(tokens1_correct, None)
    pronoun_res_c = resolve_pronouns(tokens2_correct, state1_c)
    score2_c, state2_c = score_parse(tokens2_correct, state1_c)
    
    print(f"   â†’ CÃ¼mle 1 Cf: {state1_c.forward_centers[:3]}")
    print(f"   â†’ CÃ¼mle 2 Cf: {state2_c.forward_centers[:3]}, Cb: {state2_c.backward_center or 'YOK'}")
    if pronoun_res_c:
        print(f"   â†’ Zamir Ã§Ã¶zÃ¼mÃ¼: {pronoun_res_c}")
    else:
        print(f"   â†’ Zamir Ã§Ã¶zÃ¼mÃ¼: YOK")
    print(f"   â†’ SKOR: {score2_c}")
    
    # YanlÄ±ÅŸ versiyonu test et
    print(f"\nâŒ HATA VERSÄ°YONU:")
    print(f"   CÃ¼mle 1: {wrong_pair[0]}")
    print(f"   CÃ¼mle 2: {wrong_pair[1]}")
    
    tokens1_wrong = parse_with_stanza(nlp, wrong_pair[0])
    tokens2_wrong = parse_with_stanza(nlp, wrong_pair[1])
    
    score1_w, state1_w = score_parse(tokens1_wrong, None)
    pronoun_res_w = resolve_pronouns(tokens2_wrong, state1_w)
    score2_w, state2_w = score_parse(tokens2_wrong, state1_w)
    
    print(f"   â†’ CÃ¼mle 1 Cf: {state1_w.forward_centers[:3]}")
    print(f"   â†’ CÃ¼mle 2 Cf: {state2_w.forward_centers[:3]}, Cb: {state2_w.backward_center or 'YOK'}")
    if pronoun_res_w:
        print(f"   â†’ Zamir Ã§Ã¶zÃ¼mÃ¼: {pronoun_res_w}")
    else:
        print(f"   â†’ Zamir Ã§Ã¶zÃ¼mÃ¼: YOK")
    print(f"   â†’ SKOR: {score2_w}")
    
    # KarÅŸÄ±laÅŸtÄ±rma
    print(f"\nğŸ“Š KARÅILAÅTIRMA:")
    if score2_c > score2_w:
        print(f"   âœ… Centering doÄŸru versiyonu tespit etti! ({score2_c} > {score2_w})")
        return True
    elif score2_c < score2_w:
        print(f"   âŒ Centering yanlÄ±ÅŸ versiyonu tercih etti ({score2_w} > {score2_c})")
        return False
    else:
        print(f"   âš–ï¸  Her iki versiyon eÅŸit skor aldÄ± ({score2_c} = {score2_w})")
        return None


def main():
    print("\n" + "â–ˆ"*80)
    print("ğŸš€ MERKEZLEME KURAMI: HATA TÃœRLERÄ° ANALÄ°ZÄ°")
    print("â–ˆ"*80)
    print("\n| Hata TÃ¼rÃ¼      | Centering neyi fark eder?          |")
    print("| -------------- | ---------------------------------- |")
    print("| POS hatasÄ±     | Zamir Ã§Ã¶zÃ¼mÃ¼ kopar                 |")
    print("| Role hatasÄ±    | Ã–zne merkez olmaktan dÃ¼ÅŸer         |")
    print("| Attachment     | VarlÄ±k kaybolur                    |")
    print("| Chunking       | Ã–nceki merkez Ã¶bek iÃ§inde yok olur |")
    print("| Koreferans     | SÃ¶ylem var, anlam yok              |")
    print("| Topic drift    | Cb tamamen kaybolur                |")
    print("| Segmentation   | Cf kaotikleÅŸir                     |")
    print("| Overconfidence | YapÄ± doÄŸru, sÃ¶ylem yanlÄ±ÅŸ          |")
    print("| LLM hatasÄ±     | AkÄ±cÄ± ama merkezsiz                |")
    
    # Stanza'yÄ± baÅŸlat
    print("\nâ³ Stanza Turkish modeli yÃ¼kleniyor...")
    nlp = stanza.Pipeline('tr', processors='tokenize,pos,lemma,depparse', verbose=False)
    print("âœ… Model yÃ¼klendi!\n")
    
    # 1. POS HATASI - Zamir Ã§Ã¶zÃ¼mÃ¼ kopar
    # Ã–zel durum: Manuel olarak simÃ¼le edilecek (Stanza genelde doÄŸru etiketler)
    analyze_error_type(
        nlp,
        "POS HatasÄ±",
        "Zamir Ã§Ã¶zÃ¼mÃ¼ kopar - 'O' PRON olmalÄ± ama DET etiketlenirse",
        correct_pair=("Ahmet markete gitti.", "O sÃ¼t aldÄ±."),  # O=PRON ise Ã§Ã¶zÃ¼mlenir
        wrong_pair=("Ahmet markete gitti.", "O anda sÃ¼t aldÄ±.")  # "O anda" â†’ O=DET olabilir
    )
    
    # 2. ROLE HATASI - Ã–zne merkez olmaktan dÃ¼ÅŸer
    # Pasif cÃ¼mle kullanarak Ã¶znenin rol Ã¶nemini test edelim
    analyze_error_type(
        nlp,
        "Role HatasÄ± (Dependency)",
        "Ã–zne merkez olmaktan dÃ¼ÅŸer - Pasif yapÄ±da Ã¶zne kaybÄ±",
        correct_pair=("Ahmet mektubu yazdÄ±.", "O gÃ¶nderdi."),  # Ahmet=nsubj (Ã¶zne)
        wrong_pair=("Mektup Ahmet tarafÄ±ndan yazÄ±ldÄ±.", "O gÃ¶nderdi.")  # Ahmet=obl (dolaylÄ±)
    )
    
    # 3. ATTACHMENT HATASI - VarlÄ±k kaybolur
    # Ä°yelik eki ile attachment belirsizliÄŸi
    analyze_error_type(
        nlp,
        "Attachment HatasÄ±",
        "VarlÄ±k kaybolur - Ä°yelik belirsizliÄŸi",
        correct_pair=("AyÅŸe'nin kedisi uyuyor.", "O Ã§ok sevimli."),  # kedi=merkez
        wrong_pair=("AyÅŸe kedisinin yanÄ±nda.", "O Ã§ok sevimli.")  # kedi/AyÅŸe belirsiz
    )
    
    # 4. CHUNKING HATASI - Ã–nceki merkez Ã¶bek iÃ§inde yok olur
    # BileÅŸik isim kullanarak chunking Ã¶nemini gÃ¶sterelim
    analyze_error_type(
        nlp,
        "Chunking HatasÄ±",
        "Ã–nceki merkez Ã¶bek iÃ§inde yok olur - BileÅŸik isim parÃ§alanmasÄ±",
        correct_pair=("YazÄ±lÄ±m mÃ¼hendisi geldi.", "O kod yazdÄ±."),  # "yazÄ±lÄ±m mÃ¼hendisi"=1 Ã¶bek
        wrong_pair=("YazÄ±lÄ±m mÃ¼hendisi geldi.", "YazÄ±lÄ±m gÃ¼zel.")  # sadece "yazÄ±lÄ±m" kaldÄ±
    )
    
    # 5. KOREFERANS HATASI - SÃ¶ylem var, anlam yok
    # SayÄ± uyumsuzluÄŸu net gÃ¶sterelim
    analyze_error_type(
        nlp,
        "Koreferans HatasÄ±",
        "SÃ¶ylem var, anlam yok - SayÄ± uyumsuzluÄŸu (tekil/Ã§oÄŸul)",
        correct_pair=("Ã–ÄŸrenciler sÄ±nÄ±fa girdi.", "Onlar oturdu."),  # Ã§oÄŸulâ†’Ã§oÄŸul âœ…
        wrong_pair=("Ã–ÄŸrenciler sÄ±nÄ±fa girdi.", "O oturdu.")  # Ã§oÄŸulâ†’tekil âŒ
    )
    
    # 6. TOPIC DRIFT - Cb tamamen kaybolur
    # âœ… Bu zaten iyi Ã§alÄ±ÅŸÄ±yor
    analyze_error_type(
        nlp,
        "Topic Drift",
        "Cb tamamen kaybolur - Konu tamamen deÄŸiÅŸir",
        correct_pair=("Ahmet kitap okuyor.", "O Ã§ok beÄŸendi."),  # merkez sÃ¼rekli
        wrong_pair=("Ahmet kitap okuyor.", "Hava Ã§ok gÃ¼zel.")  # konu koptu
    )
    
    # 7. SEGMENTATION HATASI - Cf kaotikleÅŸir
    # CÃ¼mle sÄ±nÄ±rÄ± belirsizliÄŸi ile forward centers karÄ±ÅŸÄ±r
    analyze_error_type(
        nlp,
        "Segmentation HatasÄ±",
        "Cf kaotikleÅŸir - YanlÄ±ÅŸ cÃ¼mle bÃ¶lÃ¼mleme",
        correct_pair=("Ali uyuyor.", "AyÅŸe Ã§alÄ±ÅŸÄ±yor."),  # iki ayrÄ± cÃ¼mle
        wrong_pair=("Ali uyuyor AyÅŸe.", "Ã‡alÄ±ÅŸÄ±yor.")  # yanlÄ±ÅŸ bÃ¶lÃ¼ndÃ¼
    )
    
    # 8. OVERCONFIDENCE - YapÄ± doÄŸru, sÃ¶ylem yanlÄ±ÅŸ
    # Semantik uyumsuzluk: centering yapÄ±sal olarak doÄŸru gÃ¶rÃ¼r ama anlam yanlÄ±ÅŸ
    analyze_error_type(
        nlp,
        "Overconfidence",
        "YapÄ± doÄŸru, sÃ¶ylem yanlÄ±ÅŸ - Animacy uyumsuzluÄŸu",
        correct_pair=("Ã‡ocuk parkta oynadÄ±.", "O yoruldu."),  # insan eylemi âœ…
        wrong_pair=("TaÅŸ parkta oynadÄ±.", "O yoruldu.")  # cansÄ±z eylem âŒ
    )
    
    # 9. LLM HATASI - AkÄ±cÄ± ama merkezsiz
    # âœ… Bu zaten iyi Ã§alÄ±ÅŸÄ±yor
    analyze_error_type(
        nlp,
        "LLM HatasÄ±",
        "AkÄ±cÄ± ama merkezsiz - Ara sÃ¶z baÄŸlamÄ± koparÄ±r",
        correct_pair=("Ahmet yemek yedi.", "O doydu."),  # doÄŸrudan baÄŸlantÄ±
        wrong_pair=("Ahmet yemek yedi.", "Afiyet olsun doydu.")  # ara sÃ¶z baÄŸlamÄ± kesti
    )
    
    print("\n" + "â–ˆ"*80)
    print("ğŸ’¡ GELÄ°ÅTÄ°RÄ°LMÄ°Å MERKEZLEME KURAMI - SONUÃ‡LAR")
    print("â–ˆ"*80)
    
    print("\nğŸ†• YENÄ° Ã–ZELLÄ°KLER:")
    print("   âœ… SayÄ± uyumu kontrolÃ¼ (tekil/Ã§oÄŸul)")
    print("   âœ… Animacy (canlÄ±lÄ±k) skoru")
    print("   âœ… Noun phrase chunking (bileÅŸik isimler)")
    print("   âœ… Ceza mekanizmasÄ± (uyumsuzluklar iÃ§in)")
    
    print("\nğŸ“Š Ä°YÄ°LEÅTÄ°RME ETKÄ°SÄ°:")
    print("   â€¢ Koreferans hatasÄ±: SayÄ± uyumsuzluÄŸu artÄ±k cezalandÄ±rÄ±lÄ±yor")
    print("   â€¢ Overconfidence: CansÄ±z varlÄ±klar ÅŸahÄ±s zamiri alamÄ±yor")
    print("   â€¢ Chunking: BileÅŸik isimler tek varlÄ±k olarak iÅŸleniyor")
    
    print("\nâœ… Merkezleme KuramÄ± ÅunlarÄ± Tespit Edebilir:")
    print("   1. POS hatalarÄ±nÄ± (zamir Ã§Ã¶zÃ¼mÃ¼ kopmasÄ±)")
    print("   2. Dependency hatalarÄ±nÄ± (rol deÄŸiÅŸimi)")
    print("   3. Attachment hatalarÄ±nÄ± (varlÄ±k kaybÄ±)")
    print("   4. Chunking hatalarÄ±nÄ± (Ã¶bek parÃ§alanmasÄ±) ğŸ†•")
    print("   5. Koreferans hatalarÄ±nÄ± (sayÄ±/kiÅŸi uyumsuzluÄŸu) ğŸ†•")
    print("   6. Topic drift'i (merkez kaybÄ±)")
    print("   7. Segmentation hatalarÄ±nÄ± (Cf kaos)")
    print("   8. Anlam hatalarÄ±nÄ± (overconfidence) ğŸ†•")
    print("   9. LLM Ã¼retim hatalarÄ±nÄ± (merkezsiz akÄ±cÄ±lÄ±k)")
    
    print("\nğŸ“ˆ Centering Metrikleri:")
    print("   â€¢ YÃ¼ksek skor (2-3): TutarlÄ± sÃ¶ylem, doÄŸru parse")
    print("   â€¢ DÃ¼ÅŸÃ¼k skor (1): HatalÄ± parse veya sÃ¶ylem kopukluÄŸu")
    print("   â€¢ Cb varlÄ±ÄŸÄ±: Merkez sÃ¼rekliliÄŸi")
    print("   â€¢ Zamir Ã§Ã¶zÃ¼mÃ¼: POS doÄŸruluÄŸu + sayÄ± uyumu")
    print("   â€¢ Cf tutarlÄ±lÄ±ÄŸÄ±: YapÄ±sal doÄŸruluk + noun phrases")


if __name__ == "__main__":
    main()
